---
title: "PML Course Project"
author: "Yashan Wang"
date: "2021/1/24"
output: html_document
---

```{r global_options, include=FALSE, fig.height=3.5, fig.width=5}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

```{r, echo=FALSE}
library(kernlab)
library(dplyr)
library(knitr)
library(tidyverse)
library(ggplot2)
library(car)
library(caret)
library(Hmisc)
library(splines)
library(randomForest)
```


## Loading data and exploratory analysis

```{r}
pml.training<-read.csv("pml-training.csv")
pml.testing<-read.csv("pml-testing.csv")
summary(pml.training$classe)
qplot(X, classe, data = pml.training, colour= user_name)
```

The outcome we were interested was the classe which was a categorical varible that had 5 levels and each of the levels contained the 6 users. A **random forest** could be used to predict which category each obs belongs to. 

However, there were 159 covariates. By observering the variables, we could see that some of them had less observations and were generated by other variables, such as avg_roll_belt or var_yaw_arm (1). So I decided to remove those variables and let machine learning algorithm to create variables using a **principal components analysis** as preprocess.

## Building model for the project  

### 1. Data cleaning and creating partition

First, redundant variables were removed from the training set. 3/4 of the trainingset was used to train the model and 1/4 was used as validation for calculating out of sample error.  

```{r}
pml.training1<-pml.training[,c(2:11,37:49,60:68,84:86,102,113:124,140,151:160)]
set.seed(666)
inTrain<-createDataPartition(y=pml.training1$classe,p=0.75,list = F)
training<-pml.training1[inTrain,]
validation<-pml.training1[-inTrain,]
dim(training);dim(validation)
```

### 2. Configure parallel processing in trControl

To improve the processing of random forest models in caret package, Dr. Leonard Greski (2) offered a parallel processing.

```{r}
library(foreach);library(iterators)
library(parallel);library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5, allowParallel = TRUE)
```

### 3. Developing random forest model

Here I used **train** function in **caret** package , **trainControl** object we built, and **pca preProcess** to build a random forest model. 

```{r}
fit2<-train(classe ~.,data = training,
            method="rf", preProcess="pca",
            trControl= fitControl)
```

### 4. De-register parallel processing cluster

```{r}
stopCluster(cluster)
registerDoSEQ()
```

### 5. Using the model to predict validation set

Checking model accuracy on training set.  

```{r}
confusionMatrix.train(fit2)
```

Checking out of sample accuracy on validation set.  

```{r}
predValid<-predict(fit2,validation)
confusionMatrix(predValid, validation$classe)
```


## Predict test dataset

At last, I implemented my model to predict the classe of the testing set given.

```{r}
pml.testing1<-pml.testing[,c(2:11,37:49,60:68,84:86,102,113:124,140,151:159)]
pml.testing1[,"classe"]<-0
pred<-predict(fit2,pml.testing1)
pred
```


#### Reference:  
1. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.  

2. [https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md]




